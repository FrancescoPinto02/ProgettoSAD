
TEST CHI QUADRO (VARIABILI CATEGORICHE / TARGET)
```{r}
# Librerie necessarie
library(dplyr)
library(here)

# Funzione per calcolare il Cramer's V
cramers_v <- function(contingency_table) {
  chi2 <- chisq.test(contingency_table)$statistic  # Statistica chi-quadro
  n <- sum(contingency_table)  # Totale osservazioni
  k <- min(dim(contingency_table))  # Numero minimo tra righe e colonne
  V <- sqrt(chi2 / (n * (k - 1)))  # Formula di Cramer's V
  return(as.numeric(V))  # Restituisce il valore di V
}

# Caricamento Dataset
data <- read.csv(here("dataset/data_aggregated.csv"), sep = ",", header = TRUE, check.names = TRUE)
colnames(data)[colnames(data) == "Daytime.evening_attendance."] <- "Attendance"

# Lista feature categoriche (escludendo il Target)
categorical_features <- c("Gender", "Marital_status", "Nationality", "Debtor", "Scholarship_holder", "Tuition_fees_up_to_date", 
                          "Mothers_qualification", "Fathers_qualification", "Mothers_occupation", "Fathers_occupation", 
                          "Displaced", "Attendance", "Educational_special_needs", "International", "Application_mode", 
                          "Application_order", "Previous_qualification", "Course")

# Inizializzare tabella per salvare i risultati globali del Chi-quadrato e Cramer's V
chi_square_results <- data.frame(Feature = character(), p_value = numeric(), Cramers_V = numeric(), Significativo = character(), stringsAsFactors = FALSE)

# Esecuzione del test del Chi-quadrato per ogni feature categorica rispetto al Target
for (feature in categorical_features) {
  
  # Creazione tabella di contingenza
  contingency_table <- table(data[[feature]], data$Target)
  
  # Controllo se la tabella di contingenza ha celle con meno di 5 osservazioni
  if(min(contingency_table) < 5){
    warning(paste("Attenzione: La variabile", feature, "ha celle con meno di 5 osservazioni. Il test potrebbe non essere affidabile."))
  }
  
  # Esecuzione test Chi-quadro
  chi_test <- chisq.test(contingency_table)
  p_value <- chi_test$p.value
  
  # Calcolo del Cramer's V
  V <- cramers_v(contingency_table)
  
  # Determinare se il risultato è significativo
  significance <- ifelse(p_value < 0.05, "SI", "NO")
  
  # Aggiunta dei risultati alla tabella globale
  chi_square_results <- rbind(chi_square_results, 
                              data.frame(Feature = feature, p_value = p_value, Cramers_V = V, Significativo = significance, stringsAsFactors = FALSE))
}

# Ordinare i risultati in base al p-value (dal più significativo al meno significativo)
chi_square_results <- chi_square_results %>% arrange(p_value)

# Salvare i risultati globali
write.csv(chi_square_results, here("RisultatiTestStatistici/chi_square_results.csv"), row.names = FALSE)
print("Risultati del test del Chi-quadro e Cramer's V salvati in 'chi_square_results.csv'.")


### Test Post-Hoc SOLO per le Feature Significative con Correzione Benjamini-Hochberg

# Selezioniamo solo le feature risultate significative
significant_features <- chi_square_results %>% filter(Significativo == "SI") %>% pull(Feature)

# Inizializzare tabella per salvare i risultati post-hoc
posthoc_results <- data.frame(Feature = character(), 
                              Comparison = character(), 
                              p_value = numeric(), 
                              p_value_adj = numeric(), 
                              Significativo = character(),
                              stringsAsFactors = FALSE)

# Livelli della variabile target
target_levels <- sort(unique(data$Target))  # Assicuriamoci di avere i livelli in ordine

# Per ogni feature categorica significativa eseguiamo confronti a coppie sui livelli del Target
for (feature in significant_features) {
  
  # Creazione della tabella di contingenza
  contingency_table <- table(data[[feature]], data$Target)
  
  # Creiamo le combinazioni a coppie dei livelli del target
  comparisons <- combn(target_levels, 2, simplify = FALSE)
  p_values_raw <- c()  # Salveremo i p-value non corretti per questa feature
  
  # Per ogni confronto a coppie
  for (comp in comparisons) {
    # Selezioniamo la sotto-tabella per i livelli specifici
    sub_table <- contingency_table[, comp, drop = FALSE]
    
    # Eseguiamo il test Chi-quadro
    test_result <- chisq.test(sub_table)
    p_val <- test_result$p.value
    p_values_raw <- c(p_values_raw, p_val)
    
    # Aggiungiamo temporaneamente il risultato (p_value_adj verrà aggiornato in seguito)
    posthoc_results <- rbind(posthoc_results, 
                             data.frame(Feature = feature, 
                                        Comparison = paste(comp, collapse = " vs "), 
                                        p_value = p_val, 
                                        p_value_adj = NA, 
                                        Significativo = ifelse(p_val < 0.05, "SI", "NO"),
                                        stringsAsFactors = FALSE))
  }
  
  # Applichiamo la correzione Benjamini-Hochberg ai p-value relativi alla feature corrente
  idx_feature <- which(posthoc_results$Feature == feature)
  p_adj <- p.adjust(posthoc_results$p_value[idx_feature], method = "BH")
  
  # Aggiorniamo i p_value aggiustati e la significatività in base al p_value corretto
  posthoc_results$p_value_adj[idx_feature] <- p_adj
  posthoc_results$Significativo[idx_feature] <- ifelse(p_adj < 0.05, "SI", "NO")
}

# Ordinare i risultati post-hoc per feature e per p_value_adj
posthoc_results <- posthoc_results[order(posthoc_results$Feature, posthoc_results$p_value_adj), ]

# Visualizzare i risultati post-hoc
print(posthoc_results)

# Salvare i risultati post-hoc in CSV
write.csv(posthoc_results, here("RisultatiTestStatistici/chi_square_posthoc_results.csv"), row.names = FALSE)
print("Risultati del test post-hoc con correzione Benjamini-Hochberg salvati in 'chi_square_posthoc_results.csv'.")


```

TEST NORMALITÀ
```{r}
# Librerie necessarie
library(dplyr)
library(here)

# Caricamento Dataset
file_path <- here::here("dataset/data_aggregated.csv")
data <- read.csv(file_path, sep = ",", header = TRUE, check.names = FALSE)

# Lista delle variabili da testare
grade_features <- c("Admission_grade", "Previous_qualification_(grade)", 
                    "Curricular_units_1st_sem_(grade)", "Curricular_units_2nd_sem_(grade)")

# ✅ Controllare i nomi delle colonne
print(colnames(data))

# ✅ Correggere i filtri usando i `backticks`
data <- data %>%
  filter(`Admission_grade` >= 95 & `Admission_grade` <= 200,
         `Previous_qualification_(grade)` >= 95 & `Previous_qualification_(grade)` <= 200)

# ✅ Filtrare i dati validi per i voti del primo e secondo semestre (range 10-20, eliminare righe con 0)
data <- data %>%
  filter(`Curricular_units_1st_sem_(grade)` > 0 & `Curricular_units_1st_sem_(grade)` >= 10 & `Curricular_units_1st_sem_(grade)` <= 20,
         `Curricular_units_2nd_sem_(grade)` > 0 & `Curricular_units_2nd_sem_(grade)` >= 10 & `Curricular_units_2nd_sem_(grade)` <= 20)

# ✅ Controllare se i dati non sono vuoti dopo i filtri
if (nrow(data) == 0) {
  stop("Errore: Dopo i filtri, non ci sono dati disponibili per eseguire il test del Chi-quadrato.")
}

# Funzione per eseguire il test del Chi-quadrato
perform_chi_square_test <- function(feature, num_bins) {
  
  # ✅ Verificare se la colonna è vuota dopo i filtri
  if (all(is.na(data[[feature]]))) {
    warning(paste("Attenzione: La variabile", feature, "non ha dati validi dopo i filtri. Test saltato."))
    return(data.frame(Feature = feature, P_Value = NA))
  }
  
  # Creare intervalli (bin)
  breaks <- seq(min(data[[feature]], na.rm = TRUE), max(data[[feature]], na.rm = TRUE), length.out = num_bins + 1)
  
  # ✅ Controllare se min e max sono finiti
  if (!is.finite(min(breaks)) || !is.finite(max(breaks))) {
    warning(paste("Attenzione: Intervalli non validi per", feature, "- Test saltato."))
    return(data.frame(Feature = feature, P_Value = NA))
  }
  
  # Creare le classi (binned data)
  data$bins <- cut(data[[feature]], breaks = breaks, include.lowest = TRUE)
  
  # Calcolare le frequenze osservate
  obs_freq <- table(data$bins)
  
  # Generare le frequenze attese da una distribuzione normale
  mean_value <- mean(data[[feature]], na.rm = TRUE)
  sd_value <- sd(data[[feature]], na.rm = TRUE)
  expected_probs <- pnorm(breaks, mean = mean_value, sd = sd_value)  # Probabilità cumulative
  expected_freq <- diff(expected_probs) * nrow(data)  # Frequenze attese
  expected_freq <- expected_freq[expected_freq > 0]  # Rimuovere valori negativi
  
  # ✅ Controllare se ci sono frequenze attese valide
  if (length(expected_freq) != length(obs_freq)) {
    warning(paste("Errore nel calcolo delle frequenze attese per", feature, "- Test saltato."))
    return(data.frame(Feature = feature, P_Value = NA))
  }
  
  # Eseguire il test del Chi-quadrato
  chi_test <- chisq.test(obs_freq, p = expected_freq / sum(expected_freq))
  
  # Restituire il risultato
  return(data.frame(Feature = feature, P_Value = chi_test$p.value))
}

# Numero di bin per ogni variabile
num_bins_list <- list("Admission_grade" = 10, "Previous_qualification_(grade)" = 10, 
                      "Curricular_units_1st_sem_(grade)" = 5, "Curricular_units_2nd_sem_(grade)" = 5)

# Eseguire il test per ogni feature
chi_square_results <- do.call(rbind, lapply(names(num_bins_list), function(feature) {
  perform_chi_square_test(feature, num_bins_list[[feature]])
}))

# Ordinare i risultati per p-value
chi_square_results <- chi_square_results %>% arrange(P_Value)

# Stampare i risultati
print(chi_square_results)

# Salvataggio dei risultati in CSV
write.csv(chi_square_results, here("RisultatiTestStatistici/chi_square_normality_results.csv"), row.names = FALSE)

print("Risultati del test del Chi-quadrato salvati in 'chi_square_normality_results.csv'.")


```


TEST KRUSKAL WALLIS (VARIABILI NUMERICHE / TARGET)
```{r}
# Librerie necessarie
library(dplyr)
library(here)

# Caricamento del dataset
file_path <- here::here("dataset/data_aggregated.csv")
data <- read.csv(file_path, sep = ",", header = TRUE, check.names = FALSE)

# 📌 Definire tutte le variabili numeriche da testare
numerical_features <- c("Admission_grade", "Previous_qualification_(grade)", 
                        "Curricular_units_1st_sem_(grade)", "Curricular_units_2nd_sem_(grade)", 
                        "Age_at_enrollment", "Unemployment_rate", "Inflation_rate", "GDP",
                        "Curricular_units_1st_sem_(credited)", "Curricular_units_1st_sem_(enrolled)",
                        "Curricular_units_1st_sem_(evaluations)", "Curricular_units_1st_sem_(approved)",
                        "Curricular_units_1st_sem_(without_evaluations)", "Curricular_units_2nd_sem_(credited)",
                        "Curricular_units_2nd_sem_(enrolled)", "Curricular_units_2nd_sem_(evaluations)",
                        "Curricular_units_2nd_sem_(approved)", "Curricular_units_2nd_sem_(without_evaluations)")

# 📌 Filtrare i dati prima di eseguire il test
data_filtered <- data %>%
  filter(`Curricular_units_1st_sem_(enrolled)` > 0 & `Curricular_units_2nd_sem_(enrolled)` > 0) %>%
  filter(!(`Curricular_units_1st_sem_(evaluations)` == 0 & `Curricular_units_2nd_sem_(evaluations)` == 0))

# 📌 Inizializzare un dataframe per i risultati del test di Kruskal-Wallis
kruskal_results <- data.frame(Feature = character(), 
                              P_Value = numeric(), 
                              Epsilon_Squared = numeric(), 
                              Significativo = character(), 
                              stringsAsFactors = FALSE)

# 📌 Eseguire il test di Kruskal-Wallis per ciascuna variabile numerica rispetto alla variabile Target
for (feature in numerical_features) {
  
  if (!(feature %in% colnames(data_filtered))) next
  if (!is.numeric(data_filtered[[feature]])) next
  if (sum(!is.na(data_filtered[[feature]])) < 3) next
  
  kruskal_test <- kruskal.test(data_filtered[[feature]] ~ data_filtered$Target, data = data_filtered)
  p_value <- kruskal_test$p.value
  
  n <- nrow(data_filtered)
  H <- kruskal_test$statistic
  epsilon_squared <- H / (n - 1)
  
  significance <- ifelse(p_value < 0.05, "SI", "NO")
  
  kruskal_results <- rbind(kruskal_results, 
                           data.frame(Feature = feature, 
                                      P_Value = p_value, 
                                      Epsilon_Squared = epsilon_squared, 
                                      Significativo = significance, 
                                      stringsAsFactors = FALSE))
}

# 📌 Ordinare i risultati e salvarli
kruskal_results <- kruskal_results %>% arrange(P_Value)
write.csv(kruskal_results, here("RisultatiTestStatistici/kruskal_wallis_results.csv"), row.names = FALSE)
print("Risultati del test di Kruskal-Wallis salvati in 'kruskal_wallis_results.csv'.")

# 🔹 **Test Post-Hoc di Dunn con correzione Benjamini-Hochberg**
# Selezionare solo le feature significative
significant_features <- kruskal_results %>% filter(Significativo == "SI") %>% pull(Feature)

# Inizializzare dataframe per risultati post-hoc
dunn_results_df <- data.frame(Feature = character(), 
                              Comparison = character(), 
                              P_Value = numeric(), 
                              P_Value_Adj = numeric(), 
                              Significativo = character(), 
                              stringsAsFactors = FALSE)

# 📌 Funzione per calcolare il test di Dunn manualmente
dunn_test_manual <- function(feature_data, target_data) {
  groups <- unique(target_data)
  comparisons <- combn(groups, 2, simplify = FALSE)
  p_values <- numeric()
  names_list <- character()
  
  for (comp in comparisons) {
    g1 <- feature_data[target_data == comp[1]]
    g2 <- feature_data[target_data == comp[2]]
    
    if (length(g1) < 2 | length(g2) < 2) next
    
    test_res <- wilcox.test(g1, g2)
    p_values <- c(p_values, test_res$p.value)
    names_list <- c(names_list, paste(comp[1], "vs", comp[2]))
  }
  
  if (length(p_values) > 0) {
    p_values_adj <- p.adjust(p_values, method = "BH")
    return(data.frame(Comparison = names_list, P_Value = p_values, P_Value_Adj = p_values_adj))
  } else {
    return(NULL)
  }
}

# 📌 Eseguire il test post-hoc solo sulle feature significative
for (feature in significant_features) {
  feature_data <- data_filtered[[feature]]
  target_data <- data_filtered$Target
  
  dunn_res <- dunn_test_manual(feature_data, target_data)
  
  if (!is.null(dunn_res)) {
    dunn_res$Feature <- feature
    dunn_res$Significativo <- ifelse(dunn_res$P_Value_Adj < 0.05, "SI", "NO")
    dunn_results_df <- rbind(dunn_results_df, dunn_res)
  }
}

# 📌 Ordinare i risultati post-hoc e salvarli
dunn_results_df <- dunn_results_df %>% arrange(Feature, P_Value_Adj)
write.csv(dunn_results_df, here("RisultatiTestStatistici/kruskal_wallis_posthoc_dunn_results.csv"), row.names = FALSE)
print("Risultati del test post-hoc di Dunn salvati in 'kruskal_wallis_posthoc_dunn_results.csv'.")


```

